{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2608.001300 기계학습 기초 및 전기정보 응용<br> Assignment 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset load & Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('data.csv', delimiter=',')\n",
    "X = data[:, :2]\n",
    "y = data[:, 2]\n",
    "label_mask = np.equal(y, 1)\n",
    "\n",
    "plt.scatter(X[:, 0][label_mask], X[:, 1][label_mask], color='red')\n",
    "plt.scatter(X[:, 0][~label_mask], X[:, 1][~label_mask], color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1-1. sklearn model로 Logistic Regression 모델 train 시켜보기\n",
    "scikit-learn library의 LogisticRegression 클래스를 이용해 train 시켜 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learn_and_return_weights(X, y):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    # YOUR CODE COMES HERE\n",
    "        \n",
    "    # w: coefficient of the model to input features,\n",
    "    # b: bias of the model\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_data_and_weights(X, y, w, b):\n",
    "    plt.scatter(X[:, 0][label_mask], X[:, 1][label_mask], color='red')\n",
    "    plt.scatter(X[:, 0][~label_mask], X[:, 1][~label_mask], color='blue')\n",
    "\n",
    "    x_lin = np.arange(20, 70)\n",
    "    y_lin = -(0.5 + b + w[0] * x_lin) / w[1]\n",
    "\n",
    "    plt.plot(x_lin, y_lin, color='black');\n",
    "    plt.show()\n",
    "\n",
    "w, b = learn_and_return_weights(X, y)\n",
    "plot_data_and_weights(X, y, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1-2. numpy로 Logistic Regression 짜보기\n",
    "scikit-learn library를 사용하지 않고 Logistic Regression을 구현해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learn_and_return_weights_numpy(X, y):\n",
    "    # YOUR CODE COMES HERE\n",
    "    \n",
    "    # w: coefficient of the model to input features,\n",
    "    # b: bias of the model\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w, b = learn_and_return_weights_numpy(X, y)\n",
    "plot_data_and_weights(X, y, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2. sklearn model로 Logistic Regression 모델 train 시켜보기 + regularizer 사용하기\n",
    "scikit-learn library의 Logistic Regression 에 대한 API문서 (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)를 읽어보고, L1-regularization을 사용할 때와 L2-regularization을 사용할 때의 weight의 변화를 살펴보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def learn_and_return_weights_l1_regularized(X, y):    \n",
    "    # YOUR CODE COMES HERE\n",
    "\n",
    "    return w, b\n",
    "\n",
    "def learn_and_return_weights_l2_regularized(X, y):    \n",
    "    # YOUR CODE COMES HERE\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    D = 1000\n",
    "    N = 80\n",
    "\n",
    "    X = np.random.random((N, D))\n",
    "    w = np.zeros(D)\n",
    "    w[0] = 1\n",
    "    w[1] = 1\n",
    "    \n",
    "    e = np.random.random(N) - 0.5\n",
    "    \n",
    "    y_score = np.dot(X, w)\n",
    "    y_score_median = np.median(y_score)\n",
    "    print(y_score.max(), y_score.min(), y_score_median)\n",
    "    \n",
    "    # y_score += 0.01 * e\n",
    "    y = y_score >= y_score_median\n",
    "    y = y.astype(np.int32)\n",
    "    \n",
    "    return (X[:N // 2], y[:N // 2]), (X[N // 2:], y[N // 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = get_dataset()\n",
    "\n",
    "w_l1, b_l1 = learn_and_return_weights_l1_regularized(x_train, y_train)\n",
    "w_l2, b_l2 = learn_and_return_weights_l2_regularized(x_train, y_train)\n",
    "\n",
    "print(w_l1[:5])\n",
    "print(w_l2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 3. Logistic Regression으로 multi-class classification 하기\n",
    "Logistic Regression은 기본적으로 binary classifier 입니다. 즉, input *X*를 2개의 class로 밖에 분류하지 못합니다. 하지만, 이같은 Logistic Regression 모델을 연달아 사용한다면 data를 여러 class로 분류할 수도 있겠죠?\n",
    "\n",
    "참고: https://en.wikipedia.org/wiki/Multiclass_classification#Transformation_to_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE COMES IN THIS CELL\n",
    "\n",
    "def classifier(x):    \n",
    "    return y # return label from x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    from keras.datasets import mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape((-1, 28 * 28)).astype(np.float32)\n",
    "    x_test = x_test.reshape((-1, 28 * 28)).astype(np.float32)\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "(x_train, y_train), (x_test, y_test) = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = np.array([classifier(x) for x in x_test])\n",
    "accuracy = np.sum(preds == y_test) / y_test.shape[0]\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
