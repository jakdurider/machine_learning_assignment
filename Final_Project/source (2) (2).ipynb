{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from data_utils import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn, cudnn_rnn\n",
    "from tensorflow.keras import layers\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D,ConvLSTM2DCell\n",
    "from keras.layers.convolutional import Conv3D\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "import keras.regularizers\n",
    "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, LSTM, Activation, Lambda, Reshape\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data functions\n",
    "\n",
    "def get_train_batch(batch_size, n_seq=10000, T=10, K=10, dir='Data/train_sequence/'):\n",
    "    selected_idx = random.sample(range(n_seq), batch_size)\n",
    "    input = np.zeros([batch_size, T, 64, 64, 3])\n",
    "    \n",
    "    output = np.zeros([batch_size, K, 64, 64, 3])\n",
    "    for i, idx in enumerate(selected_idx):\n",
    "        for t in range(T+K):\n",
    "            img_path = os.path.join(dir, 'sequence%04d' % idx, 'frames%02d.png' % t)\n",
    "            img = np.array(Image.open(img_path)) / 255.0  # normalize\n",
    "            if t < 10:\n",
    "                input[i, t] = img\n",
    "            else:\n",
    "                output[i, t-10] = img\n",
    "    \n",
    "    \n",
    "    return input, output\n",
    "\n",
    "\n",
    "def get_val_batch(start, end, T=10, K=10, dir='Data/val_sequence/'):\n",
    "    input = np.zeros([end-start, T, 64, 64, 3])\n",
    "    output = np.zeros([end-start, K, 64, 64, 3])\n",
    "    for i, idx in enumerate(range(start, end)):\n",
    "        for t in range(T+K):\n",
    "            img_path = os.path.join(dir, 'sequence%03d' % idx, 'frames%02d.png' % t)\n",
    "            img = np.array(Image.open(img_path)) / 255.0  # normalize\n",
    "            if t < 10:\n",
    "                input[i, t] = img\n",
    "            else:\n",
    "                output[i, t-10] = img\n",
    "\n",
    "    return input, output\n",
    "\n",
    "\n",
    "def get_test_batch(start, end, T=10, dir='Data/test_sequence/'):\n",
    "    input = np.zeros([end-start, T, 64, 64, 3])\n",
    "    for i, idx in enumerate(range(start, end)):\n",
    "        for t in range(T):\n",
    "            img_path = os.path.join(dir, 'sequence%03d' % idx, 'frames%02d.png' % t)\n",
    "            img = np.array(Image.open(img_path)) / 255.0  # normalize\n",
    "            input[i, t] = img\n",
    "\n",
    "    return input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "training_size=512\n",
    "batch_size=128\n",
    "learning_rate=0.001\n",
    "num_layers=2 # layer num of LSTM\n",
    "num_hidden=64 # state num of LSTM??\n",
    "timesteps=10\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "train_input, train_output= get_train_batch(training_size)\n",
    "val_input, val_output= get_val_batch(start=0,end=500)\n",
    "test_input = get_test_batch(start=0,end=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_reshape_version=np.reshape(train_input[:,-1],(training_size,1,64,64,3))\n",
    "\n",
    "train_output_shift=np.concatenate((train_reshape_version,train_output[:,:9]),axis=1)\n",
    "\n",
    "val_reshape_version=np.reshape(val_input[:,-1],(500,1,64,64,3))\n",
    "\n",
    "val_output_shift=np.concatenate((val_reshape_version,val_output[:,:9]),axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10, 64, 64, 3)\n",
      "(500, 10, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(val_input.shape)\n",
    "print(val_output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "## make autoencoder\n",
    "\n",
    "input_img = Input(shape=(64, 64, 3)) \n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# meaningful feature: (8,8,16) dimension\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu',padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encoder model\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## decoder model\n",
    "encoded_input = Input(shape=(8,8,16))\n",
    "\n",
    "decoder_layer = autoencoder.layers[7:]\n",
    "get_decoded=decoder_layer[0](encoded_input)\n",
    "for i in range(1,7):\n",
    "    get_decoded=decoder_layer[i](get_decoded)\n",
    "decoder = Model(encoded_input, get_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5120 samples, validate on 5000 samples\n",
      "Epoch 1/50\n",
      "5120/5120 [==============================] - 18s 3ms/step - loss: 0.2182 - val_loss: 0.0725\n",
      "Epoch 2/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0594 - val_loss: 0.0550\n",
      "Epoch 3/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0537 - val_loss: 0.0517\n",
      "Epoch 4/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0507 - val_loss: 0.0492\n",
      "Epoch 5/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0467 - val_loss: 0.0432\n",
      "Epoch 6/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0405 - val_loss: 0.0379\n",
      "Epoch 7/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0372 - val_loss: 0.0365\n",
      "Epoch 8/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0357 - val_loss: 0.0350\n",
      "Epoch 9/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0348 - val_loss: 0.0352\n",
      "Epoch 10/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0344 - val_loss: 0.0338\n",
      "Epoch 11/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0337 - val_loss: 0.0337\n",
      "Epoch 12/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0333 - val_loss: 0.0335\n",
      "Epoch 13/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0328 - val_loss: 0.0328\n",
      "Epoch 14/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0323 - val_loss: 0.0321\n",
      "Epoch 15/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0320 - val_loss: 0.0313\n",
      "Epoch 16/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0314 - val_loss: 0.0311\n",
      "Epoch 17/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0313 - val_loss: 0.0312\n",
      "Epoch 18/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0310 - val_loss: 0.0312\n",
      "Epoch 19/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0308 - val_loss: 0.0301\n",
      "Epoch 20/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0304 - val_loss: 0.0299\n",
      "Epoch 21/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0301 - val_loss: 0.0297\n",
      "Epoch 22/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0298 - val_loss: 0.0300\n",
      "Epoch 23/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0297 - val_loss: 0.0296\n",
      "Epoch 24/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0295 - val_loss: 0.0290\n",
      "Epoch 25/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0293 - val_loss: 0.0290\n",
      "Epoch 26/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0290 - val_loss: 0.0288\n",
      "Epoch 27/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0289 - val_loss: 0.0287\n",
      "Epoch 28/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0285 - val_loss: 0.0277\n",
      "Epoch 29/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0285 - val_loss: 0.0286\n",
      "Epoch 30/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0283 - val_loss: 0.0282\n",
      "Epoch 31/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0283 - val_loss: 0.0275\n",
      "Epoch 32/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0279 - val_loss: 0.0280\n",
      "Epoch 33/50\n",
      "5120/5120 [==============================] - 6s 1ms/step - loss: 0.0279 - val_loss: 0.0277\n",
      "Epoch 34/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0278 - val_loss: 0.0281\n",
      "Epoch 35/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0276 - val_loss: 0.0274\n",
      "Epoch 36/50\n",
      "5120/5120 [==============================] - 6s 1ms/step - loss: 0.0275 - val_loss: 0.0271\n",
      "Epoch 37/50\n",
      "5120/5120 [==============================] - 6s 1ms/step - loss: 0.0274 - val_loss: 0.0269\n",
      "Epoch 38/50\n",
      "5120/5120 [==============================] - 6s 1ms/step - loss: 0.0273 - val_loss: 0.0268\n",
      "Epoch 39/50\n",
      "5120/5120 [==============================] - 6s 1ms/step - loss: 0.0272 - val_loss: 0.0268\n",
      "Epoch 40/50\n",
      "5120/5120 [==============================] - 6s 1ms/step - loss: 0.0271 - val_loss: 0.0266\n",
      "Epoch 41/50\n",
      "5120/5120 [==============================] - 6s 1ms/step - loss: 0.0268 - val_loss: 0.0268\n",
      "Epoch 42/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0270 - val_loss: 0.0268\n",
      "Epoch 43/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0268 - val_loss: 0.0265\n",
      "Epoch 44/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0266 - val_loss: 0.0266\n",
      "Epoch 45/50\n",
      "5120/5120 [==============================] - 6s 1ms/step - loss: 0.0266 - val_loss: 0.0263\n",
      "Epoch 46/50\n",
      "5120/5120 [==============================] - 6s 1ms/step - loss: 0.0265 - val_loss: 0.0263\n",
      "Epoch 47/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0264 - val_loss: 0.0263\n",
      "Epoch 48/50\n",
      "5120/5120 [==============================] - 7s 1ms/step - loss: 0.0263 - val_loss: 0.0262\n",
      "Epoch 49/50\n",
      "3840/5120 [=====================>........] - ETA: 1s - loss: 0.0261"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-4edca8e0d542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_input_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_input_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    185\u001b[0m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## training autoencoder\n",
    "train_input_reshape=np.reshape(train_input,(training_size*10,64,64,3))\n",
    "val_input_reshape=np.reshape(val_input,(500*10,64,64,3))\n",
    "autoencoder.fit(train_input_reshape, train_input_reshape,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(val_input_reshape, val_input_reshape),\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## show images\n",
    "\n",
    "\n",
    "decoded_imgs_toshow = autoencoder.predict(val_input_reshape)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(val_input_reshape[i].reshape(64, 64, 3))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i +1 + n)\n",
    "    plt.imshow(decoded_imgs_toshow[i].reshape(64, 64, 3))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_to_encoder(x):\n",
    "    return encoder(x)\n",
    "\n",
    "def put_to_decoder(x):\n",
    "    return decoder(x)\n",
    "\n",
    "def reshape_with_batch(x):\n",
    "    return tf.reshape(x,shape=(-1,64,64,3))\n",
    "\n",
    "def reshape_with_batch2(x):\n",
    "    return tf.reshape(x,shape=(-1,8,8,16))\n",
    "\n",
    "def reshape_apart_with_batch(x):\n",
    "    return tf.reshape(x,shape=(-1,timesteps,8,8,16))\n",
    "\n",
    "def reshape_apart_with_batch2(x):\n",
    "    return tf.reshape(x,shape=(-1,timesteps,64,64,3))\n",
    "\n",
    "def normalize(x):\n",
    "    return x*255\n",
    "\n",
    "def solve_nan(x):\n",
    "    return np.nan_to_num(x)\n",
    "\n",
    "def zero_tf(x):\n",
    "    return tf.zeros(shape=(None,timesteps,64,64,3))\n",
    "\n",
    "def encoder_stack(x):\n",
    "    x=tf.reshape(x,shape=(-1,1,8,8,16))\n",
    "    encoder_list=[]\n",
    "    for i in range(10):\n",
    "        encoder_list=encoder_list+[x]\n",
    "    return encoder_list\n",
    "\n",
    "def reshape_encoder(x):\n",
    "    return tf.reshape(x,shape=(-1,1,8,8,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convolution LSTM cell encoder level\n",
    "'''\n",
    "cells = [ConvLSTM2DCell(filters=16,kernel_size=(3,3),\n",
    "                     activation='sigmoid',padding='same',\n",
    "                     ) for i in range(num_layers)]\n",
    "\n",
    "lstm_cell = ConvLSTM2DCell(filters=16,kernel_size=(3,3),\n",
    "                     activation='sigmoid',padding='same')\n",
    "'''\n",
    "# model=Sequential()\n",
    "\n",
    "# get input image sequence\n",
    "input_img_sequence = Input(shape=(timesteps,64, 64, 3)) \n",
    "\n",
    "# put input to encoder, use later when fit\n",
    "\n",
    "input_img_sequence_reshape = Lambda(reshape_with_batch)(input_img_sequence)\n",
    "\n",
    "input_img_sequence_reshape = Lambda(put_to_encoder)(input_img_sequence_reshape)\n",
    "\n",
    "input_img_sequence_reshape = Lambda(reshape_apart_with_batch)(input_img_sequence_reshape)\n",
    "\n",
    "# put 1 layer convLSTM2D \n",
    "encoder_model,state_h,state_c = ConvLSTM2D(filters=16, kernel_size=(3,3), activation='relu',\n",
    "                            input_shape=(timesteps, 8, 8, 16), return_sequences=False,\n",
    "                           return_state=True,\n",
    "#                            kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "#                            bias_regularizer=keras.regularizers.l2(0.01),\n",
    "#                             activity_regularizer=keras.regularizers.l1(0.01),\n",
    "                            padding='same')(input_img_sequence_reshape)\n",
    "\n",
    "\n",
    "# use only states\n",
    "encoder_states=[state_h[:], state_c[:]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate_1/concat:0\", shape=(?, 10, 8, 8, 16), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Convolution LSTM cell decoder level\n",
    "\n",
    "# 1 layer of convLSTM..?\n",
    "\n",
    "#\n",
    "# decoder_input = Input(shape=(timesteps,64,64,3))\n",
    "\n",
    "# put input to encoder, use later when fit\n",
    "'''\n",
    "decoder_input=Lambda(zero_tf)(encoder_model)\n",
    "\n",
    "decoder_img_sequence_reshape = Lambda(reshape_with_batch)(decoder_input)\n",
    "\n",
    "decoder_img_sequence_reshape = Lambda(put_to_encoder)(decoder_img_sequence_reshape)\n",
    "\n",
    "decoder_img_sequence_reshape = Lambda(reshape_apart_with_batch)(decoder_img_sequence_reshape)\n",
    "'''\n",
    "\n",
    "encoder_list= Lambda(encoder_stack)(encoder_model)\n",
    "\n",
    "encoder_model = Concatenate(axis=1)(encoder_list)\n",
    "print(encoder_model)\n",
    "decoder_model = ConvLSTM2D(filters=16, kernel_size=(3,3), activation='sigmoid',\n",
    "                            input_shape=(timesteps, 8, 8, 16), \n",
    "                            return_sequences=True,\n",
    "#                       kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "#                            bias_regularizer=keras.regularizers.l2(0.01),\n",
    "#                             activity_regularizer=keras.regularizers.l1(0.01),\n",
    "                            padding='same')(encoder_model,initial_state=encoder_states)\n",
    "\n",
    "\n",
    "decoder_output = Lambda(reshape_with_batch2)(decoder_model)\n",
    "\n",
    "decoder_output = Lambda(put_to_decoder)(decoder_output)\n",
    "\n",
    "decoder_output = Lambda(reshape_apart_with_batch2)(decoder_output)\n",
    "\n",
    "decoder_output = Activation('relu')(decoder_output)\n",
    "\n",
    "# decoder_output = Lambda(solve_nan)(decoder_output)\n",
    "\n",
    "model=Model(input_img_sequence,decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 10, 64, 64, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 64, 64, 3)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 8, 8, 16)     0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 10, 8, 8, 16) 0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)     [(None, 8, 8, 16), ( 18496       lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               [(None, 1, 8, 8, 16) 0           conv_lst_m2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10, 8, 8, 16) 0           lambda_4[0][9]                   \n",
      "                                                                 lambda_4[0][9]                   \n",
      "                                                                 lambda_4[0][9]                   \n",
      "                                                                 lambda_4[0][9]                   \n",
      "                                                                 lambda_4[0][9]                   \n",
      "                                                                 lambda_4[0][9]                   \n",
      "                                                                 lambda_4[0][9]                   \n",
      "                                                                 lambda_4[0][9]                   \n",
      "                                                                 lambda_4[0][9]                   \n",
      "                                                                 lambda_4[0][9]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)     (None, 10, 8, 8, 16) 18496       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 8, 8, 16)     0           conv_lst_m2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 64, 64, 3)    0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 10, 64, 64, 3 0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 64, 64, 3 0           lambda_7[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 36,992\n",
      "Trainable params: 36,992\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 512 samples, validate on 500 samples\n",
      "Epoch 1/50\n",
      "512/512 [==============================] - 14s 27ms/step - loss: 0.0439 - acc: 0.7331 - val_loss: 0.0422 - val_acc: 0.8366\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0405 - acc: 0.8077 - val_loss: 0.0404 - val_acc: 0.6602\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0392 - acc: 0.6673 - val_loss: 0.0396 - val_acc: 0.7378\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0384 - acc: 0.7587 - val_loss: 0.0390 - val_acc: 0.7253\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0377 - acc: 0.6961 - val_loss: 0.0384 - val_acc: 0.6800\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0371 - acc: 0.7117 - val_loss: 0.0379 - val_acc: 0.7175\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0365 - acc: 0.6851 - val_loss: 0.0371 - val_acc: 0.6571\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0358 - acc: 0.6891 - val_loss: 0.0364 - val_acc: 0.7027\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0351 - acc: 0.6803 - val_loss: 0.0355 - val_acc: 0.6853\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0343 - acc: 0.6995 - val_loss: 0.0348 - val_acc: 0.6426\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0335 - acc: 0.6684 - val_loss: 0.0340 - val_acc: 0.6635\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0329 - acc: 0.6397 - val_loss: 0.0335 - val_acc: 0.6472\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0321 - acc: 0.6154 - val_loss: 0.0329 - val_acc: 0.6251\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0316 - acc: 0.6001 - val_loss: 0.0324 - val_acc: 0.6167\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0310 - acc: 0.6037 - val_loss: 0.0323 - val_acc: 0.5880\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0306 - acc: 0.5857 - val_loss: 0.0320 - val_acc: 0.5732\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0303 - acc: 0.5645 - val_loss: 0.0320 - val_acc: 0.6181\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0300 - acc: 0.5666 - val_loss: 0.0314 - val_acc: 0.5374\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0295 - acc: 0.5456 - val_loss: 0.0315 - val_acc: 0.5328\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0291 - acc: 0.5421 - val_loss: 0.0312 - val_acc: 0.5425\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0288 - acc: 0.5453 - val_loss: 0.0314 - val_acc: 0.5092\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0286 - acc: 0.5503 - val_loss: 0.0314 - val_acc: 0.5930\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0287 - acc: 0.5571 - val_loss: 0.0311 - val_acc: 0.4891\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0283 - acc: 0.5509 - val_loss: 0.0309 - val_acc: 0.5213\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0278 - acc: 0.5279 - val_loss: 0.0308 - val_acc: 0.5339\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0276 - acc: 0.5399 - val_loss: 0.0314 - val_acc: 0.5088\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0272 - acc: 0.5392 - val_loss: 0.0309 - val_acc: 0.5220\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0270 - acc: 0.5342 - val_loss: 0.0311 - val_acc: 0.4925\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0271 - acc: 0.5351 - val_loss: 0.0308 - val_acc: 0.4953\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0266 - acc: 0.5200 - val_loss: 0.0311 - val_acc: 0.5326\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0262 - acc: 0.5274 - val_loss: 0.0308 - val_acc: 0.5174\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0258 - acc: 0.5052 - val_loss: 0.0317 - val_acc: 0.5922\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0258 - acc: 0.5223 - val_loss: 0.0321 - val_acc: 0.6077\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0263 - acc: 0.5252 - val_loss: 0.0319 - val_acc: 0.5824\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0260 - acc: 0.5325 - val_loss: 0.0313 - val_acc: 0.5174\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0254 - acc: 0.5320 - val_loss: 0.0318 - val_acc: 0.4682\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0249 - acc: 0.5264 - val_loss: 0.0314 - val_acc: 0.4804\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0247 - acc: 0.5075 - val_loss: 0.0313 - val_acc: 0.5074\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0243 - acc: 0.5123 - val_loss: 0.0317 - val_acc: 0.5704\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0241 - acc: 0.5170 - val_loss: 0.0319 - val_acc: 0.5601\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0239 - acc: 0.5202 - val_loss: 0.0322 - val_acc: 0.5612\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0238 - acc: 0.5138 - val_loss: 0.0321 - val_acc: 0.5372\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0236 - acc: 0.5300 - val_loss: 0.0318 - val_acc: 0.4881\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0233 - acc: 0.5067 - val_loss: 0.0327 - val_acc: 0.5091\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0234 - acc: 0.5227 - val_loss: 0.0314 - val_acc: 0.5247\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0229 - acc: 0.5141 - val_loss: 0.0329 - val_acc: 0.5217\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0228 - acc: 0.5267 - val_loss: 0.0328 - val_acc: 0.4858\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 0.0224 - acc: 0.5140 - val_loss: 0.0332 - val_acc: 0.4707\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 0.0224 - acc: 0.5193 - val_loss: 0.0332 - val_acc: 0.4686\n",
      "Epoch 50/50\n",
      "128/512 [======>.......................] - ETA: 2s - loss: 0.0219 - acc: 0.4845"
     ]
    }
   ],
   "source": [
    "## train model\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(train_input, train_output,\n",
    "\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(val_input, val_output))\n",
    "#          callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_decoded_imgs_toshow = model.predict(val_input)\n",
    "\n",
    "number = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "for i in range(number):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(val_output[0,i].reshape(64, 64, 3))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i +1 + n)\n",
    "    plt.imshow(model_decoded_imgs_toshow[0,i].reshape(64, 64, 3))\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predicted_imgs_toshow = model.predict(test_input)\n",
    "\n",
    "for i in range(500):\n",
    "    for j in range(10):\n",
    "       \n",
    "        \n",
    "        test_img_path = os.path.join('test_predicted/','sequence%03d' % i, 'frames%02d.png' % j) \n",
    "        save_img(test_img_path,model_predicted_imgs_toshow[i][j])\n",
    "#         tf.io.write_file(test_img_path,model_predicted_imgs_toshow[i][j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
